{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import tabulate as tb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rlbase import misc\n",
    "from rlbase.environment import GridworldEx41Environment, CarRentalEnvironment, GamblerEnvironment\n",
    "from rlbase.policy import UniformPolicy, DeterministicPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "--  --  --  --\n",
      " 0  -1  -1  -1\n",
      "-1  -1  -1  -1\n",
      "-1  -1  -1  -1\n",
      "-1  -1  -1   0\n",
      "--  --  --  --\n",
      "\n",
      "Iteration:  2\n",
      "----  ----  ----  ----\n",
      " 0    -1.8  -2    -2\n",
      "-1.8  -2    -2    -2\n",
      "-2    -2    -2    -1.8\n",
      "-2    -2    -1.8   0\n",
      "----  ----  ----  ----\n",
      "\n",
      "Iteration:  3\n",
      "----  ----  ----  ----\n",
      " 0    -2.4  -2.9  -3\n",
      "-2.4  -2.9  -3    -2.9\n",
      "-2.9  -3    -2.9  -2.4\n",
      "-3    -2.9  -2.4   0\n",
      "----  ----  ----  ----\n",
      "\n",
      "Iteration:  10\n",
      "----  ----  ----  ----\n",
      " 0    -6.1  -8.4  -9\n",
      "-6.1  -7.7  -8.4  -8.4\n",
      "-8.4  -8.4  -7.7  -6.1\n",
      "-9    -8.4  -6.1   0\n",
      "----  ----  ----  ----\n",
      "\n",
      "Iteration:  425\n",
      "---  ---  ---  ---\n",
      "  0  -14  -20  -22\n",
      "-14  -18  -20  -20\n",
      "-20  -20  -18  -14\n",
      "-22  -20  -14    0\n",
      "---  ---  ---  ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = GridworldEx41Environment()\n",
    "\n",
    "pi = UniformPolicy(env=env)\n",
    "\n",
    "v, arr_v = misc.evaluate_policy_iterative(env,pi)\n",
    "\n",
    "for (i,x) in enumerate(arr_v):\n",
    "  if i in [1,2,3,10,425]:\n",
    "    print(\"Iteration: \",i)\n",
    "    env.pretty_print(env.reshape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.1\n",
    "Calculate the q-values for (s,a)=((3,1),\"down\") and (s,a)=((3,2),\"down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q((3,1),\"down\") -1.0\n",
      "q((3,2),\"down\") -15.0\n"
     ]
    }
   ],
   "source": [
    "q = misc.get_action_value_function(env,arr_v[-1])\n",
    "print('q((3,1),\"down\")',round(q((3,1),\"down\"),1))\n",
    "print('q((3,2),\"down\")',round(q((3,2),\"down\"),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ca5dff42b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimproved_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimprove_policy_from_value_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_bestaction_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimproved_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_policy_linear_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimproved_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rlbase/misc.py\u001b[0m in \u001b[0;36mimprove_policy_from_value_function\u001b[0;34m(env, values, gamma, tol)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimprove_policy_from_value_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mimproved_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'policy'"
     ]
    }
   ],
   "source": [
    "improved_policy = misc.improve_policy_from_value_function(env,v)\n",
    "env.plot_bestaction_policy(improved_policy)\n",
    "v = misc.evaluate_policy_linear_system(env,improved_policy)\n",
    "env.pretty_print(env.reshape(v))\n",
    "\n",
    "improved_policy = misc.improve_policy_from_value_function(env,v)\n",
    "env.plot_bestaction_policy(improved_policy)\n",
    "v = misc.evaluate_policy_linear_system(env,improved_policy)\n",
    "env.pretty_print(env.reshape(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4.2\n",
    "\n",
    "Jack's Car Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "env = CarRentalEnvironment()\n",
    "pi = DeterministicPolicy(env=env,best_actions={s:[0] for s in env.states})\n",
    "\n",
    "for i in range(5):\n",
    "    arr = np.zeros((env.nmax+1,env.nmax+1))\n",
    "    for i in range(env.nmax+1):\n",
    "      for j in range(env.nmax+1):\n",
    "        arr[i,j] = pi.get((i,j))\n",
    "    plt.imshow(arr, cmap='hot', interpolation='nearest',origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    v = misc.evaluate_policy_linear_system_two_args(env,pi,gamma=gamma)\n",
    "    pi = misc.improve_policy_from_value_function_two_args(env, v, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4.3 Gambler's Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "env = GamblerEnvironment(n=N)\n",
    "\n",
    "# Evaluate policy and visualize value function\n",
    "v, arr_v = misc.value_iteration_two_args(env,tol=1e-4)\n",
    "for i in arr_v:\n",
    "  plt.plot([i[j] for j in range(1,N)])\n",
    "\n",
    "plt.figure()\n",
    "arr = np.zeros((N+1,N+1))\n",
    "for s in range(1,N):\n",
    "  for a in env.actions:\n",
    "    v1 = 0\n",
    "    for (s_prime, r, p) in env.state_transition_two_args(s,a):\n",
    "      v1 += p * (r + v[s_prime])\n",
    "    arr[s,a] = v1\n",
    "plt.imshow(arr[1:99,:])\n",
    "\n",
    "pi = misc.improve_policy_from_value_function_two_args(env,v,tol=1e-3)\n",
    "\n",
    "plt.figure()\n",
    "aa = []\n",
    "ss = []\n",
    "for s in range(1,N):\n",
    "  for a in range(1,N):\n",
    "    if pi.prob(a,s)>0:\n",
    "      aa.append(a)\n",
    "      ss.append(s)\n",
    "      break\n",
    "plt.plot(ss,aa,'x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
